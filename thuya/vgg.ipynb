{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.initializers import GlorotNormal, Zeros\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Label\n",
       "0   0      1\n",
       "1   1      0\n",
       "2   2      1\n",
       "3   3      1\n",
       "4   4      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/train_label.csv\", )\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              25691136  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 3075      \n",
      "=================================================================\n",
      "Total params: 40,408,899\n",
      "Trainable params: 25,694,211\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(5242)\n",
    "target_size = (224, 224)\n",
    "no_of_classes = df['Label'].nunique()\n",
    "\n",
    "from tensorflow.keras.applications import VGG16, Xception\n",
    "\n",
    "input_shape = list(target_size) + [3]\n",
    "model =  VGG16(input_shape=input_shape, weights='imagenet', include_top=False)\n",
    "\n",
    "# don't train existing weights\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# w_init = GlorotNormal()\n",
    "\n",
    "x = Flatten()(model.output)\n",
    "# x = Dropout(0.2)(x)\n",
    "# x = Dense(256, activation=\"relu\", kernel_initializer=w_init,  kernel_regularizer=\"l2\")(x)\n",
    "# x = BatchNormalization()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.2, seed=5242)(x)\n",
    "prediction = Dense(no_of_classes, activation='softmax')(x)\n",
    "\n",
    "# create a model object\n",
    "model = Model(inputs=model.input, outputs=prediction)\n",
    "\n",
    "# view the structure of the model\n",
    "model.summary()\n",
    "\n",
    "# tell the model what cost and optimization method to use\n",
    "model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID Label Filename\n",
       "0   0     1    0.png\n",
       "1   1     0    1.png\n",
       "2   2     1    2.png\n",
       "3   3     1    3.png\n",
       "4   4     1    4.png"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Filename'] = df['ID'].apply(lambda x: \"{}.png\".format(x))\n",
    "df['Label'] = df['Label'].astype(str)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>199</td>\n",
       "      <td>0</td>\n",
       "      <td>199.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>558</td>\n",
       "      <td>0</td>\n",
       "      <td>558.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>831</td>\n",
       "      <td>0</td>\n",
       "      <td>831.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>709</td>\n",
       "      <td>0</td>\n",
       "      <td>709.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID Label Filename\n",
       "199  199     0  199.png\n",
       "558  558     0  558.png\n",
       "100  100     0  100.png\n",
       "831  831     0  831.png\n",
       "709  709     0  709.png"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_0 = df[df['Label'] == '0']\n",
    "df_1 = df[df['Label'] == '1']\n",
    "df_2 = df[df['Label'] == '2']\n",
    "\n",
    "np.random.seed(5242)\n",
    "\n",
    "min_row_count = min(df_0.shape[0], df_1.shape[0], df_2.shape[0])\n",
    "\n",
    "df_0 = df_0.sample(n=min_row_count)\n",
    "df_1 = df_1.sample(n=min_row_count)\n",
    "df_2 = df_2.sample(n=min_row_count)\n",
    "    \n",
    "df = pd.concat([df_0, df_1, df_2])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index().drop(columns=['index',  'ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 5242\n",
    "k = 3\n",
    "\n",
    "x_train = df['Filename']\n",
    "y_train = df['Label']\n",
    "folds = list(StratifiedKFold(n_splits=k, shuffle=True, random_state=random_state).split(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "                                 \n",
    "# val_datagen = ImageDataGenerator(rescale = 1./255, \n",
    "#                             shear_range = 0.1,\n",
    "#                             zoom_range = 0.1,\n",
    "#                             width_shift_range = 0.1,\n",
    "#                             height_shift_range = 0.1,\n",
    "#                             rotation_range = 10,\n",
    "#                             horizontal_flip = True,\n",
    "#                             vertical_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = os.path.join(\"checkpoint\", \"vgg16\")\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\train_image\n",
      "data\\test_image\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'data'\n",
    "\n",
    "def get_dir(data_dir, dir_name):\n",
    "    dir_1 = os.path.join(data_dir, dir_name)\n",
    "\n",
    "    if os.path.exists(dir_1):  # check target directory existence in the system\n",
    "        img_count = len(glob(\"{}/*.png\".format(dir_1)))\n",
    "\n",
    "        if img_count == 0:  # if no image is found, increase 1 more layer\n",
    "            dir_2 = os.path.join(dir_1, dir_name)\n",
    "            img_count = len(glob(\"{}/*.png\".format(dir_2)))\n",
    "\n",
    "            if img_count == 0:  # if no image is found here also, raise error\n",
    "                raise FileNotFoundError(\"!!! No images found at both {} and {} !!!\".format(dir_1, dir_2))\n",
    "            else:\n",
    "                return dir_2  # if images are found here, return this directory path instead\n",
    "\n",
    "        else:\n",
    "            return dir_1  # if images are found here, return this directory path\n",
    "\n",
    "    else:  # raise error if data directory doesn't exist\n",
    "        raise OSError(\"!!! {} folder doesn't exist !!!\".format(dir_1))\n",
    "\n",
    "train_dir = get_dir(data_dir, 'train_image')\n",
    "test_dir = get_dir(data_dir, 'test_image')\n",
    "print(train_dir)\n",
    "print(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold: 0\n",
      "Found 624 non-validated image filenames belonging to 3 classes.\n",
      "Found 312 non-validated image filenames belonging to 3 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 20 steps, validate for 10 steps\n",
      "Epoch 1/20\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 4.2358 - accuracy: 0.6267WARNING:tensorflow:From C:\\Users\\Fuzzy\\miniconda3\\envs\\CS5242_project\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: checkpoint\\vgg16\\assets\n",
      "20/20 [==============================] - 24s 1s/step - loss: 4.0953 - accuracy: 0.6346 - val_loss: 1.1907 - val_accuracy: 0.8397\n",
      "Epoch 2/20\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 0.7044 - accuracy: 0.8615INFO:tensorflow:Assets written to: checkpoint\\vgg16\\assets\n",
      "20/20 [==============================] - 16s 804ms/step - loss: 0.6875 - accuracy: 0.8638 - val_loss: 0.4339 - val_accuracy: 0.8942\n",
      "Epoch 3/20\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 0.1462 - accuracy: 0.9493INFO:tensorflow:Assets written to: checkpoint\\vgg16\\assets\n",
      "20/20 [==============================] - 16s 810ms/step - loss: 0.1401 - accuracy: 0.9519 - val_loss: 0.2444 - val_accuracy: 0.9295\n",
      "Epoch 4/20\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 0.0894 - accuracy: 0.9611INFO:tensorflow:Assets written to: checkpoint\\vgg16\\assets\n",
      "20/20 [==============================] - 16s 798ms/step - loss: 0.0868 - accuracy: 0.9631 - val_loss: 0.2172 - val_accuracy: 0.9359\n",
      "Epoch 5/20\n",
      "20/20 [==============================] - 10s 476ms/step - loss: 0.1017 - accuracy: 0.9631 - val_loss: 0.2564 - val_accuracy: 0.9199\n",
      "Epoch 6/20\n",
      "20/20 [==============================] - 10s 482ms/step - loss: 0.0507 - accuracy: 0.9760 - val_loss: 0.3252 - val_accuracy: 0.9006\n",
      "Epoch 7/20\n",
      "20/20 [==============================] - 10s 489ms/step - loss: 0.0280 - accuracy: 0.9872 - val_loss: 0.2719 - val_accuracy: 0.9038\n",
      "Epoch 8/20\n",
      "20/20 [==============================] - 10s 492ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.2972 - val_accuracy: 0.9071\n",
      "Epoch 9/20\n",
      "20/20 [==============================] - 10s 492ms/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 0.3116 - val_accuracy: 0.9038\n",
      "Epoch 10/20\n",
      "20/20 [==============================] - 10s 497ms/step - loss: 0.0087 - accuracy: 0.9952 - val_loss: 0.2438 - val_accuracy: 0.9167\n",
      "Epoch 11/20\n",
      "20/20 [==============================] - 10s 498ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2917 - val_accuracy: 0.9038\n",
      "Epoch 12/20\n",
      "20/20 [==============================] - 10s 499ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2719 - val_accuracy: 0.9135\n",
      "Epoch 13/20\n",
      "20/20 [==============================] - 10s 500ms/step - loss: 0.0029 - accuracy: 0.9984 - val_loss: 0.2534 - val_accuracy: 0.9199\n",
      "Epoch 14/20\n",
      "20/20 [==============================] - 10s 501ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2568 - val_accuracy: 0.9135\n",
      "Epoch 15/20\n",
      "20/20 [==============================] - 10s 501ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3073 - val_accuracy: 0.9103\n",
      "Epoch 16/20\n",
      "20/20 [==============================] - 10s 500ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2635 - val_accuracy: 0.9167\n",
      "Epoch 17/20\n",
      "20/20 [==============================] - 10s 499ms/step - loss: 9.0718e-04 - accuracy: 1.0000 - val_loss: 0.2644 - val_accuracy: 0.9167\n",
      "Epoch 18/20\n",
      "20/20 [==============================] - 10s 498ms/step - loss: 8.9381e-04 - accuracy: 1.0000 - val_loss: 0.2638 - val_accuracy: 0.9103\n",
      "Epoch 19/20\n",
      "20/20 [==============================] - 10s 497ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2741 - val_accuracy: 0.9103\n",
      "Epoch 20/20\n",
      "20/20 [==============================] - 10s 497ms/step - loss: 7.1075e-04 - accuracy: 1.0000 - val_loss: 0.2716 - val_accuracy: 0.9103\n",
      "\n",
      "Fold: 1\n",
      "Found 624 non-validated image filenames belonging to 3 classes.\n",
      "Found 312 non-validated image filenames belonging to 3 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 20 steps, validate for 10 steps\n",
      "Epoch 1/20\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 0.1301 - accuracy: 0.9510INFO:tensorflow:Assets written to: checkpoint\\vgg16\\assets\n",
      "20/20 [==============================] - 17s 838ms/step - loss: 0.1401 - accuracy: 0.9471 - val_loss: 0.0127 - val_accuracy: 0.9968\n",
      "Epoch 2/20\n",
      "20/20 [==============================] - 10s 478ms/step - loss: 0.1016 - accuracy: 0.9615 - val_loss: 0.0494 - val_accuracy: 0.9776\n",
      "Epoch 3/20\n",
      "20/20 [==============================] - 10s 493ms/step - loss: 0.1577 - accuracy: 0.9391 - val_loss: 0.3112 - val_accuracy: 0.9038\n",
      "Epoch 4/20\n",
      "20/20 [==============================] - 10s 495ms/step - loss: 0.0665 - accuracy: 0.9696 - val_loss: 0.0309 - val_accuracy: 0.9840\n",
      "Epoch 5/20\n",
      "20/20 [==============================] - 10s 496ms/step - loss: 0.0427 - accuracy: 0.9824 - val_loss: 0.3325 - val_accuracy: 0.8942\n",
      "Epoch 6/20\n",
      "20/20 [==============================] - 10s 498ms/step - loss: 0.0502 - accuracy: 0.9808 - val_loss: 0.0620 - val_accuracy: 0.9679\n",
      "Epoch 7/20\n",
      "20/20 [==============================] - 10s 499ms/step - loss: 0.0096 - accuracy: 0.9952 - val_loss: 0.0445 - val_accuracy: 0.9808\n",
      "Epoch 8/20\n",
      "20/20 [==============================] - 10s 496ms/step - loss: 0.0062 - accuracy: 0.9984 - val_loss: 0.0319 - val_accuracy: 0.9904\n",
      "Epoch 9/20\n",
      "20/20 [==============================] - 10s 497ms/step - loss: 9.9998e-04 - accuracy: 1.0000 - val_loss: 0.0381 - val_accuracy: 0.9840\n",
      "Epoch 10/20\n",
      "20/20 [==============================] - 10s 498ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0513 - val_accuracy: 0.9808\n",
      "Epoch 11/20\n",
      "20/20 [==============================] - 10s 499ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0327 - val_accuracy: 0.9904\n",
      "Epoch 12/20\n",
      "20/20 [==============================] - 10s 498ms/step - loss: 9.8924e-04 - accuracy: 1.0000 - val_loss: 0.0313 - val_accuracy: 0.9872\n",
      "Epoch 13/20\n",
      "20/20 [==============================] - 10s 500ms/step - loss: 2.4954e-04 - accuracy: 1.0000 - val_loss: 0.0311 - val_accuracy: 0.9872\n",
      "Epoch 14/20\n",
      "20/20 [==============================] - 10s 499ms/step - loss: 4.0619e-04 - accuracy: 1.0000 - val_loss: 0.0311 - val_accuracy: 0.9872\n",
      "Epoch 15/20\n",
      "20/20 [==============================] - 10s 499ms/step - loss: 2.3706e-04 - accuracy: 1.0000 - val_loss: 0.0310 - val_accuracy: 0.9872\n",
      "Epoch 16/20\n",
      "20/20 [==============================] - 10s 501ms/step - loss: 2.3457e-04 - accuracy: 1.0000 - val_loss: 0.0312 - val_accuracy: 0.9872\n",
      "Epoch 17/20\n",
      "20/20 [==============================] - 10s 500ms/step - loss: 3.3254e-04 - accuracy: 1.0000 - val_loss: 0.0311 - val_accuracy: 0.9872\n",
      "Epoch 18/20\n",
      "20/20 [==============================] - 10s 499ms/step - loss: 2.6297e-04 - accuracy: 1.0000 - val_loss: 0.0301 - val_accuracy: 0.9872\n",
      "Epoch 19/20\n",
      "20/20 [==============================] - 10s 501ms/step - loss: 2.1927e-04 - accuracy: 1.0000 - val_loss: 0.0299 - val_accuracy: 0.9872\n",
      "Epoch 20/20\n",
      "20/20 [==============================] - 10s 500ms/step - loss: 2.1584e-04 - accuracy: 1.0000 - val_loss: 0.0295 - val_accuracy: 0.9872\n",
      "\n",
      "Fold: 2\n",
      "Found 624 non-validated image filenames belonging to 3 classes.\n",
      "Found 312 non-validated image filenames belonging to 3 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 20 steps, validate for 10 steps\n",
      "Epoch 1/20\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 0.0136 - accuracy: 0.9932INFO:tensorflow:Assets written to: checkpoint\\vgg16\\assets\n",
      "20/20 [==============================] - 17s 846ms/step - loss: 0.0141 - accuracy: 0.9936 - val_loss: 1.7339e-04 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "20/20 [==============================] - 10s 483ms/step - loss: 0.0154 - accuracy: 0.9968 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "20/20 [==============================] - 10s 494ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "20/20 [==============================] - 10s 497ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.9127e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "20/20 [==============================] - 10s 498ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 3.9218e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "20/20 [==============================] - 10s 499ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 4.2808e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 5.5613e-04 - accuracy: 1.0000INFO:tensorflow:Assets written to: checkpoint\\vgg16\\assets\n",
      "20/20 [==============================] - 17s 843ms/step - loss: 5.4494e-04 - accuracy: 1.0000 - val_loss: 1.7245e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 3.1554e-04 - accuracy: 1.0000INFO:tensorflow:Assets written to: checkpoint\\vgg16\\assets\n",
      "20/20 [==============================] - 16s 821ms/step - loss: 3.0987e-04 - accuracy: 1.0000 - val_loss: 1.6653e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "20/20 [==============================] - 10s 481ms/step - loss: 4.7216e-04 - accuracy: 1.0000 - val_loss: 3.2730e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 3.3008e-04 - accuracy: 1.0000INFO:tensorflow:Assets written to: checkpoint\\vgg16\\assets\n",
      "20/20 [==============================] - 17s 839ms/step - loss: 3.3351e-04 - accuracy: 1.0000 - val_loss: 1.4727e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "20/20 [==============================] - 10s 483ms/step - loss: 2.6224e-04 - accuracy: 1.0000 - val_loss: 1.9255e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "20/20 [==============================] - 10s 495ms/step - loss: 2.3943e-04 - accuracy: 1.0000 - val_loss: 1.7318e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "20/20 [==============================] - 10s 501ms/step - loss: 1.6746e-04 - accuracy: 1.0000 - val_loss: 1.4758e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "20/20 [==============================] - 10s 501ms/step - loss: 2.3597e-04 - accuracy: 1.0000 - val_loss: 1.7587e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "20/20 [==============================] - 10s 505ms/step - loss: 1.8771e-04 - accuracy: 1.0000 - val_loss: 1.9130e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "20/20 [==============================] - 10s 503ms/step - loss: 1.6976e-04 - accuracy: 1.0000 - val_loss: 1.5550e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "20/20 [==============================] - 10s 502ms/step - loss: 1.6320e-04 - accuracy: 1.0000 - val_loss: 1.7887e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "20/20 [==============================] - 10s 500ms/step - loss: 1.4854e-04 - accuracy: 1.0000 - val_loss: 2.0821e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "20/20 [==============================] - 10s 500ms/step - loss: 1.6513e-04 - accuracy: 1.0000 - val_loss: 2.0062e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "20/20 [==============================] - 10s 500ms/step - loss: 1.1518e-04 - accuracy: 1.0000 - val_loss: 1.8481e-04 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "for idx, (train_idx, val_idx) in enumerate(folds):\n",
    "    print(\"\\nFold: {}\".format(idx))\n",
    "    \n",
    "    df_train = pd.DataFrame()\n",
    "    df_train['Filename'] = x_train[train_idx]\n",
    "    df_train['Label'] = y_train[train_idx]\n",
    "    df_val = pd.DataFrame()\n",
    "    df_val['Filename'] = x_train[val_idx]\n",
    "    df_val['Label'] = y_train[val_idx]\n",
    "    \n",
    "    train_generator = train_datagen.flow_from_dataframe(dataframe=df_train,\n",
    "                                              directory=train_dir, \n",
    "                                              validate_filenames=False,\n",
    "                                              x_col=\"Filename\", \n",
    "                                              y_col=\"Label\", \n",
    "                                              class_mode=\"categorical\",\n",
    "                                              target_size=target_size, \n",
    "                                              batch_size=batch_size)\n",
    "\n",
    "    validation_generator = val_datagen.flow_from_dataframe(dataframe=df_val,\n",
    "                                                  directory=train_dir, \n",
    "                                                  validate_filenames=False,\n",
    "                                                  x_col=\"Filename\", \n",
    "                                                  y_col=\"Label\", \n",
    "                                                  class_mode=\"categorical\",\n",
    "                                                  target_size=target_size, \n",
    "                                                  batch_size=batch_size)\n",
    "    model.fit(\n",
    "        train_generator,\n",
    "        epochs=20,\n",
    "        validation_data=validation_generator,\n",
    "        callbacks=[model_checkpoint_callback]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = load_model(checkpoint_filepath)\n",
    "\n",
    "test_files = glob(\"{}/*.png\".format(test_dir))\n",
    "result = []\n",
    "\n",
    "for file in test_files:\n",
    "    img = load_img(file, grayscale=False, color_mode=\"rgb\", target_size=target_size)\n",
    "    img_arr = np.array([img_to_array(img)])/255\n",
    "    predictions = best_model.predict(img_arr)\n",
    "    \n",
    "    img_id = Path(file).stem\n",
    "    result.append([img_id, np.argmax(predictions)])\n",
    "\n",
    "with open('vgg16-submission3.csv','w') as result_file:\n",
    "    wr = csv.writer(result_file)\n",
    "    wr.writerows([['ID', 'Label']])\n",
    "    wr.writerows(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_val_split(df):\n",
    "#     return np.split(df.sample(frac=1), [int(.7*len(df))])\n",
    "\n",
    "# df_0_train, df_0_val = train_val_split(df_0)\n",
    "# df_1_train, df_1_val = train_val_split(df_1)\n",
    "# df_2_train, df_2_val = train_val_split(df_2)\n",
    "\n",
    "# df_train = pd.concat([df_0_train, df_1_train, df_2_train])\n",
    "# df_val = pd.concat([df_0_val, df_1_val, df_2_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fit the model\n",
    "# r = model.fit(\n",
    "#     train_generator,\n",
    "#     epochs=20,\n",
    "#     validation_data=validation_generator,\n",
    "#     callbacks=[model_checkpoint_callback]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # loss\n",
    "# plt.plot(r.history['loss'], label='train loss')\n",
    "# plt.plot(r.history['val_loss'], label='val loss')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(18, 4))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.title('Loss')\n",
    "# plt.plot(r.history['loss'], label=\"train loss\")\n",
    "# plt.plot(r.history['val_loss'], label=\"val loss\")\n",
    "\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.title('Accuracy')\n",
    "# plt.plot(r.history['accuracy'], label=\"train accuracy\")\n",
    "# plt.plot(r.history['val_accuracy'], label=\"val accuracy\")\n",
    "\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
